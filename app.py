import streamlit as st
import openai
from PIL import Image
import base64
import io
import json
import requests
from typing import List, Dict
import time
import os
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

st.set_page_config(
    page_title="Object Extractor",
    page_icon="ğŸ¨",
    layout="wide"
)

def encode_image_to_base64(image: Image.Image) -> str:
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return img_str

def detect_objects(client: openai.OpenAI, image: Image.Image) -> List[Dict]:
    base64_image = encode_image_to_base64(image)
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "Analyze this image thoroughly and identify ALL visible objects, including both large and small items, details, and parts of objects. Be comprehensive and include: main objects, background elements, small details, accessories, decorative items, furniture parts, natural elements, etc. If there are multiple objects of the same type, list each one separately with specific positions (for example: if there are 2 trees, list them as 'upper tree' and 'lower tree'). Please respond in the following JSON format: {\"objects\": [{\"object_ja\": \"object name in Japanese\", \"object_en\": \"object name in English\", \"position_ja\": \"position in Japanese (e.g., å³ä¸Š, ä¸­å¤®, å·¦ä¸‹)\", \"position_en\": \"position in English (e.g., upper right, center, lower left)\"}, ...]}"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
        response_format={"type": "json_object"},
        max_tokens=1000
    )
    
    try:
        response_text = response.choices[0].message.content
        response_data = json.loads(response_text)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—
        if 'objects' in response_data:
            return response_data['objects']
        elif isinstance(response_data, list):
            return response_data
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å€¤ã‹ã‚‰é…åˆ—ã‚’æ¢ã™
            for value in response_data.values():
                if isinstance(value, list):
                    return value
            return []
    except (json.JSONDecodeError, IndexError, AttributeError, KeyError) as e:
        st.error(f"ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡ºã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return []


def generate_object_image(client: openai.OpenAI, original_image: Image.Image, obj: Dict, quality: str = "low", size: str = "1024x1024") -> str:
    # ç”»åƒç·¨é›†ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ - ã‚¢ãƒ¬ãƒ³ã‚¸ç¦æ­¢ã€å®Œå…¨ä¸€è‡´ã‚’è¦æ±‚ï¼ˆè‹±èªç‰ˆã‚’ä½¿ç”¨ï¼‰
    object_en = obj.get('object_en', obj.get('object', ''))
    position_en = obj.get('position_en', obj.get('position', ''))
    prompt = f"Extract EXACTLY the {object_en} at {position_en} from this image. CRITICAL: Do not modify, enhance, stylize, or change ANYTHING about the {object_en}. Keep it 100% identical to the original - exact same colors, exact same textures, exact same lighting, exact same shadows, exact same proportions, exact same details, exact same angle, exact same orientation, exact same perspective, exact same viewpoint. Only remove the background and other objects by making them transparent. NO artistic interpretation, NO improvements, NO style changes, NO color adjustments, NO rotation, NO angle changes, NO perspective changes. Perfect pixel-level accuracy required. Maintain the EXACT same viewing angle and orientation as shown in the original image."
    
    # å…ƒç”»åƒã‚’ãƒã‚¤ãƒˆå½¢å¼ã«å¤‰æ›ï¼ˆæ­£ã—ã„MIMEã‚¿ã‚¤ãƒ—æŒ‡å®šï¼‰
    import io
    img_byte_arr = io.BytesIO()
    original_image.save(img_byte_arr, format='PNG')
    img_byte_arr.seek(0)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ä½œæˆï¼ˆMIMEã‚¿ã‚¤ãƒ—æŒ‡å®šï¼‰
    from io import BytesIO
    
    try:
        response = client.images.edit(
            model="gpt-image-1",
            image=("image.png", img_byte_arr, "image/png"),
            prompt=prompt,
            size=size,
            quality=quality,
            n=1,
            output_format="png",
            background="transparent"
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        if response.data and len(response.data) > 0:
            first_item = response.data[0]
            
            # URLã¾ãŸã¯b64_jsonã®ç¢ºèª
            if hasattr(first_item, 'url') and first_item.url:
                return first_item.url
            elif hasattr(first_item, 'b64_json') and first_item.b64_json:
                import base64
                # ãƒ‡ãƒ¼ã‚¿URIã‚¹ã‚­ãƒ¼ãƒ å½¢å¼ã§è¿”ã™ï¼ˆStreamlitãŒè¡¨ç¤ºå¯èƒ½ï¼‰
                data_uri = f"data:image/png;base64,{first_item.b64_json}"
                return data_uri
            else:
                st.error("âŒ URLã‚‚b64_jsonã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
        else:
            st.error("âŒ ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return None
        
    except Exception as e:
        st.error(f"âŒ gpt-image-1 ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
        
        # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
        if hasattr(e, 'response') and e.response is not None:
            st.write(f"HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {e.response.status_code}")
            try:
                error_body = e.response.json()
                st.write(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_body}")
            except:
                st.write(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ: {e.response.text}")
        
        st.write(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
        return None

def download_image(url_or_data_uri: str) -> bytes:
    try:
        # ãƒ‡ãƒ¼ã‚¿URIã®å ´åˆã®å‡¦ç†
        if url_or_data_uri.startswith("data:image/"):
            import base64
            # ãƒ‡ãƒ¼ã‚¿URIã‹ã‚‰Base64éƒ¨åˆ†ã‚’æŠ½å‡º
            base64_data = url_or_data_uri.split(",")[1]
            return base64.b64decode(base64_data)
        else:
            # é€šå¸¸ã®URLã®å ´åˆã®å‡¦ç†
            response = requests.get(url_or_data_uri)
            response.raise_for_status()
            return response.content
    except Exception as e:
        st.error(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    st.title("ğŸ¨ Object Extractor")
    st.markdown("ç”»åƒã‹ã‚‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æŠ½å‡ºã—ã€å€‹åˆ¥ã®ç”»åƒã¨ã—ã¦å†ç”Ÿæˆã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™")
    
    # APIã‚­ãƒ¼ã®å–å¾—ï¼ˆLOCAL=1ã®å ´åˆã®ã¿ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ã€ãã‚Œä»¥å¤–ã¯UIå…¥åŠ›ï¼‰
    st.sidebar.header("è¨­å®š")
    
    # LOCALç’°å¢ƒå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯
    is_local = os.getenv("LOCAL") == "1"
    
    if is_local:
        # LOCAL=1ã®å ´åˆã€ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
        env_api_key = os.getenv("OPENAI_API_KEY")
        if env_api_key:
            api_key = env_api_key
            st.sidebar.success("âœ… APIã‚­ãƒ¼ãŒç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ")
        else:
            st.sidebar.error("âŒ LOCAL=1ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ãŒã€OPENAI_API_KEYãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            api_key = None
    else:
        # LOCAL!=1ã®å ´åˆã€UIå…¥åŠ›ã‚’è¦æ±‚
        api_key = st.sidebar.text_input(
            "OpenAI API Key", 
            type="password",
            help="OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
        )
    
    # ç”»åƒç”Ÿæˆè¨­å®š
    st.sidebar.subheader("ç”»åƒç”Ÿæˆè¨­å®š")
    image_quality = st.sidebar.selectbox(
        "ç”»åƒå“è³ª",
        options=["high", "medium", "low"],
        index=1,
        help="high: é«˜å“è³ª, medium: ä¸­å“è³ªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰, low: ä½å“è³ª"
    )
    
    image_size = st.sidebar.selectbox(
        "ç”»åƒã‚µã‚¤ã‚º",
        options=["1024x1024", "1024x1536", "1536x1024"],
        index=0,
        help="1024x1024: æ­£æ–¹å½¢, 1024x1536: ç¸¦é•·, 1536x1024: æ¨ªé•·"
    )
    
    if not api_key:
        st.warning("OpenAI API ã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        return
    
    client = openai.OpenAI(api_key=api_key)
    
    # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    st.header("ğŸ“· ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader(
        "ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['png', 'jpg', 'jpeg'],
        help="PNGã€JPGã€JPEGå½¢å¼ã®ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™"
    )
    
    if uploaded_file is not None:
        # ç”»åƒè¡¨ç¤º
        image = Image.open(uploaded_file)
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ")
            st.image(image, use_column_width=True)
        
        with col2:
            if st.button("ğŸ” ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œå‡º", type="primary"):
                with st.spinner("ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œå‡ºä¸­..."):
                    objects = detect_objects(client, image)
                
                if objects:
                    st.session_state.objects = objects
                    st.session_state.original_image = image
                    st.success(f"{len(objects)}å€‹ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼")
                else:
                    st.error("ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®æ¤œå‡ºã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®è¡¨ç¤ºã¨é¸æŠ
    if hasattr(st.session_state, 'objects') and st.session_state.objects:
        st.header("ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ")
        
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆé¸æŠUI
        st.subheader("ç”Ÿæˆã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„")
        
        # å…¨é¸æŠ/å…¨è§£é™¤ãƒœã‚¿ãƒ³
        col1, col2 = st.columns(2)
        with col1:
            if st.button("âœ… å…¨ã¦é¸æŠ"):
                for i in range(len(st.session_state.objects)):
                    st.session_state[f"select_obj_{i}"] = True
        with col2:
            if st.button("âŒ å…¨ã¦è§£é™¤"):
                for i in range(len(st.session_state.objects)):
                    st.session_state[f"select_obj_{i}"] = False
        
        # å„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é¸æŠãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹
        selected_objects = []
        for i, obj in enumerate(st.session_state.objects):
            key = f"select_obj_{i}"
            if key not in st.session_state:
                st.session_state[key] = False
            
            object_ja = obj.get('object_ja', obj.get('object', ''))
            object_en = obj.get('object_en', obj.get('object', ''))
            position_ja = obj.get('position_ja', obj.get('position', ''))
            position_en = obj.get('position_en', obj.get('position', ''))
            
            is_selected = st.checkbox(
                f"**{object_ja}** (ä½ç½®: {position_ja})",
                value=st.session_state[key],
                key=key,
                help=f"è‹±èª: {object_en} at {position_en}"
            )
            
            if is_selected:
                selected_objects.append((i, obj))
        
        # é¸æŠã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç”»åƒç”Ÿæˆ
        if selected_objects:
            st.write(f"é¸æŠã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: {len(selected_objects)}å€‹")
            
            # ç¾åœ¨ã®è¨­å®šã‚’è¡¨ç¤º
            st.info(f"ç”»åƒè¨­å®š: å“è³ª={image_quality}, ã‚µã‚¤ã‚º={image_size}")
            
            if st.button("ğŸ¨ é¸æŠã—ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç”»åƒã‚’ç”Ÿæˆ", type="primary"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                if 'generated_images' not in st.session_state:
                    st.session_state.generated_images = {}
                
                for i, (obj_index, obj) in enumerate(selected_objects):
                    object_ja = obj.get('object_ja', obj.get('object', ''))
                    position_ja = obj.get('position_ja', obj.get('position', ''))
                    status_text.text(f"ç”Ÿæˆä¸­: {object_ja} ({i+1}/{len(selected_objects)})")
                    
                    image_url = generate_object_image(client, st.session_state.original_image, obj, image_quality, image_size)
                    
                    if image_url and image_url != "None":
                        st.session_state.generated_images[f"{object_ja}_{position_ja}"] = image_url
                    else:
                        st.error(f"âŒ {object_ja} ã®ç”»åƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    
                    progress_bar.progress((i + 1) / len(selected_objects))
                    time.sleep(1)  # APIåˆ¶é™ã‚’è€ƒæ…®ã—ãŸå¾…æ©Ÿ
                
                status_text.text("ç”Ÿæˆå®Œäº†ï¼")
                st.success("é¸æŠã—ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç”»åƒç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            st.info("ç”»åƒã‚’ç”Ÿæˆã™ã‚‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    
    # ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®è¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    if hasattr(st.session_state, 'generated_images') and st.session_state.generated_images:
        st.header("ğŸ–¼ï¸ ç”Ÿæˆã•ã‚ŒãŸç”»åƒ")
        
        cols = st.columns(5)  # 5åˆ—ã«å¢—åŠ 
        for i, (obj_key, image_url) in enumerate(st.session_state.generated_images.items()):
            with cols[i % 5]:
                st.write(f"**{obj_key.replace('_', ' - ')}**")
                
                try:
                    st.image(image_url, width=150)  # å›ºå®šå¹…ã§å°ã•ãè¡¨ç¤º
                except Exception as e:
                    st.error(f"ç”»åƒè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                image_data = download_image(image_url)
                if image_data:
                    st.download_button(
                        label="ğŸ’¾",  # ãƒœã‚¿ãƒ³ã‚‚å°ã•ã
                        data=image_data,
                        file_name=f"{obj_key}.png",
                        mime="image/png",
                        key=f"download_{i}"
                    )

if __name__ == "__main__":
    main()
